"""
LLM Parser - Parse m√¥ t·∫£ nh√† ti·∫øng Vi·ªát th√†nh features
======================================================
S·ª≠ d·ª•ng HuggingFace Inference API (FREE)

Usage:
    from llm_parser import LLMParser
    
    parser = LLMParser(token="hf_xxxxxxxxxx")
    features = parser.parse("Nh√† 100m2, 3PN, 2WC, qu·∫≠n 7, s·ªï h·ªìng")
    # Output: {'Area': 100, 'Bedrooms': 3, 'Bathrooms': 2, 'District': 'Qu·∫≠n 7', 'LegalStatus': 'S·ªï h·ªìng'}
"""

import json
import re
from typing import Dict, Any, List, Optional
from huggingface_hub import InferenceClient


class LLMParser:
    """
    Parse m√¥ t·∫£ nh√† ti·∫øng Vi·ªát th√†nh dictionary features s·ª≠ d·ª•ng LLM
    
    Attributes:
        token: HuggingFace API token
        models: List models ƒë·ªÉ th·ª≠
        
    Example:
        parser = LLMParser(token="hf_xxxxxxxxxx")
        features = parser.parse("Nh√† 100m2, 3PN, qu·∫≠n 7")
    """
    
    # Models m·∫∑c ƒë·ªãnh (ƒë√£ test ho·∫°t ƒë·ªông)
    DEFAULT_MODELS = [
        "Qwen/Qwen2.5-72B-Instruct",
        "google/gemma-2-2b-it",
    ]
    
    def __init__(self, token: str = None, models: List[str] = None):
        """
        Kh·ªüi t·∫°o LLM Parser
        
        Args:
            token: HuggingFace token (l·∫•y t·∫°i https://huggingface.co/settings/tokens)
                   Token Type: "Read"
            models: List models ƒë·ªÉ th·ª≠ (None = d√πng DEFAULT_MODELS)
            
        Raises:
            ValueError: N·∫øu token kh√¥ng h·ª£p l·ªá
        """
        # Ki·ªÉm tra token
        if token is None or token == "SetTokenHere":
            raise ValueError(
                "\n" + "=" * 60 +
                "\n‚ùå CH∆ØA SET TOKEN!"
                "\n" + "-" * 60 +
                "\nC√°ch l·∫•y token:"
                "\n  1. V√†o: https://huggingface.co/settings/tokens"
                "\n  2. Click 'Create new token'"
                "\n  3. Ch·ªçn Token Type: 'Read'"
                "\n  4. Copy token (b·∫Øt ƒë·∫ßu b·∫±ng 'hf_')"
                "\n\nC√°ch d√πng:"
                "\n  parser = LLMParser(token='hf_xxxxxxxxxx')"
                "\n" + "=" * 60
            )
        
        if not token.startswith("hf_"):
            raise ValueError("Token ph·∫£i b·∫Øt ƒë·∫ßu b·∫±ng 'hf_'")
        
        self.token = token
        self.models = models or self.DEFAULT_MODELS
        self._client = InferenceClient(token=token)
    
    def parse(self, text: str, verbose: bool = True) -> Dict[str, Any]:
        """
        Parse m√¥ t·∫£ nh√† th√†nh dictionary features
        
        Args:
            text: M√¥ t·∫£ nh√†, vd: "Nh√† 100m2, 3PN, 2WC, qu·∫≠n 7, s·ªï h·ªìng"
            verbose: In log hay kh√¥ng
            
        Returns:
            Dict v·ªõi c√°c features ƒë√£ extract, vd:
            {
                'Area': 100,
                'Bedrooms': 3,
                'Bathrooms': 2,
                'District': 'Qu·∫≠n 7',
                'LegalStatus': 'S·ªï h·ªìng'
            }
            
        C√°c tr∆∞·ªùng c√≥ th·ªÉ tr·∫£ v·ªÅ:
            - Area: di·ªán t√≠ch (m2)
            - Bedrooms: s·ªë ph√≤ng ng·ªß
            - Bathrooms: s·ªë toilet/WC
            - Floors: s·ªë t·∫ßng
            - Frontage: m·∫∑t ti·ªÅn (m)
            - AccessRoad: ƒë∆∞·ªùng tr∆∞·ªõc nh√† (m)
            - Direction: h∆∞·ªõng nh√†
            - BalconyDirection: h∆∞·ªõng ban c√¥ng
            - District: qu·∫≠n/huy·ªán
            - Ward: ph∆∞·ªùng/x√£
            - City: th√†nh ph·ªë
            - LegalStatus: ph√°p l√Ω
            - Furniture: n·ªôi th·∫•t
        """
        prompt = self._build_prompt(text)
        messages = [{"role": "user", "content": prompt}]
        
        for model in self.models:
            model_name = model.split('/')[-1]
            try:
                if verbose:
                    print(f"üîÑ {model_name}...", end=" ")
                
                response = self._client.chat_completion(
                    model=model,
                    messages=messages,
                    max_tokens=300,
                    temperature=0.1,
                )
                
                result_text = response.choices[0].message.content.strip()
                parsed = self._extract_json(result_text)
                
                if parsed:
                    if verbose:
                        print("‚úÖ")
                    return parsed
                
                if verbose:
                    print("‚ö†Ô∏è JSON r·ªóng")
                    
            except Exception as e:
                if verbose:
                    print(f"‚ùå {str(e)[:40]}")
                continue
        
        if verbose:
            print("‚ùå T·∫•t c·∫£ models ƒë·ªÅu th·∫•t b·∫°i!")
        return {}
    
    def _build_prompt(self, text: str) -> str:
        """T·∫°o prompt cho LLM"""
        return f"""Tr√≠ch xu·∫•t th√¥ng tin b·∫•t ƒë·ªông s·∫£n t·ª´ c√¢u ti·∫øng Vi·ªát sau th√†nh JSON.

C√¢u: "{text}"

C√°c tr∆∞·ªùng c·∫ßn tr√≠ch xu·∫•t (ch·ªâ tr·∫£ v·ªÅ nh·ªØng tr∆∞·ªùng c√≥ trong c√¢u):
- Area: di·ªán t√≠ch (s·ªë, m2)
- Bedrooms: s·ªë ph√≤ng ng·ªß
- Bathrooms: s·ªë toilet/WC
- Floors: s·ªë t·∫ßng
- Frontage: m·∫∑t ti·ªÅn (m)
- AccessRoad: ƒë∆∞·ªùng tr∆∞·ªõc nh√† (m)
- Direction: h∆∞·ªõng nh√†
- BalconyDirection: h∆∞·ªõng ban c√¥ng
- District: qu·∫≠n/huy·ªán
- Ward: ph∆∞·ªùng/x√£
- City: th√†nh ph·ªë
- LegalStatus: ph√°p l√Ω (s·ªï ƒë·ªè, s·ªï h·ªìng...)
- Furniture: n·ªôi th·∫•t

CH·ªà TR·∫¢ V·ªÄ JSON THU·∫¶N T√öY, KH√îNG GI·∫¢I TH√çCH.
V√≠ d·ª•: {{"Area": 100, "Bedrooms": 3, "District": "Qu·∫≠n 7"}}"""
    
    def _extract_json(self, text: str) -> dict:
        """Extract JSON t·ª´ response text"""
        text = text.strip()
        
        # Th·ª≠ parse tr·ª±c ti·∫øp
        try:
            return json.loads(text)
        except:
            pass
        
        # T√¨m JSON trong text
        patterns = [
            r'```json\s*([\s\S]*?)\s*```',
            r'```\s*([\s\S]*?)\s*```',
            r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}',
            r'\{.*?\}',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text, re.DOTALL)
            if match:
                try:
                    json_str = match.group(1) if '```' in pattern else match.group()
                    return json.loads(json_str.strip())
                except:
                    continue
        
        return {}


# ============================================
# TEST
# ============================================

if __name__ == "__main__":
    import sys
    
    print("=" * 60)
    print("üè† LLM PARSER TEST")
    print("=" * 60)
     
    token = "set token here"  # Thay b·∫±ng token c·ªßa b·∫°n
    
    if not token:
        print("‚ùå Kh√¥ng c√≥ token!")
        sys.exit(1)
    
    # Kh·ªüi t·∫°o parser
    try:
        parser = LLMParser(token=token)
    except ValueError as e:
        print(e)
        sys.exit(1)
    
    # Test cases
    test_cases = [
        "B√°n nh√† 120m2, 3 ph√≤ng ng·ªß, 2 toilet, qu·∫≠n 7, s·ªï h·ªìng, h∆∞·ªõng ƒë√¥ng nam",
        "Nh√† ph·ªë 80m2 B√¨nh Th·∫°nh, 4 t·∫ßng, full n·ªôi th·∫•t cao c·∫•p",
        "B√°n g·∫•p cƒÉn nh√† 200m2, 5PN, 4WC, m·∫∑t ti·ªÅn 6m, qu·∫≠n 1",
        "Nh√† h·∫ªm 5m, 60m2, 2 l·∫ßu, ph∆∞·ªùng T√¢n ƒê·ªãnh, qu·∫≠n 1, gi√° 4 t·ª∑",
    ]
    
    for text in test_cases:
        print(f"\nüìù Input: {text}")
        features = parser.parse(text)
        print(f"üìã Output: {features}")
        print("-" * 60)